{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = os.getcwd()\n",
    "subjDirs = []\n",
    "for subjDir in os.listdir(repo):\n",
    "    if os.path.isdir(subjDir) & (fnmatch.fnmatch(subjDir, 'GroupID')):\n",
    "        subjDirs.append(subjDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeropad(n,zeros=3):\n",
    "    \"Pad number n with zeros. Example: zeropad(7,3) == '007'\"\n",
    "    nstr = str(n)\n",
    "    while len(nstr) < zeros:\n",
    "        nstr = \"0\" + nstr\n",
    "    return nstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merging script\n",
    "def processInput(subj):\n",
    "    \n",
    "    ## set the consensus matrix (thresholded at 15%)\n",
    "    # initial module partition\n",
    "    mod_init = np.genfromtxt(subj + '/modOut/clink_thr150.clu', delimiter=None)\n",
    "    df_mod_init = pd.DataFrame(mod_init, columns=['node_ID', 'module', 'flow'])\n",
    "\n",
    "    # consensus matrix\n",
    "    consMat = np.zeros((333,333))\n",
    "    for roi in range(1,334):\n",
    "        roi_mask = df_mod_init.isin([roi])\n",
    "        row_roi = list(roi_mask['node_ID'][roi_mask['node_ID'] == True].index)\n",
    "        for roi2 in range(1,334):\n",
    "            roi2_mask = df_mod_init.isin([roi2])\n",
    "            row_roi2 = list(roi2_mask['node_ID'][roi2_mask['node_ID'] == True].index)\n",
    "            if (df_mod_init.loc[row_roi,'module'].values == df_mod_init.loc[row_roi2,'module'].values):\n",
    "                consMat[roi-1,roi2-1] = 1\n",
    "    \n",
    "    \n",
    "    ## iteratively update the consensus matrix from threshold of 0.15 to 0.01 by 0.001\n",
    "    ## takes less than 12 hrs/subj\n",
    "    for thr in reversed(range(10,150)):\n",
    "\n",
    "        # load the modularity data (node ID, module, flow) of all tresholded connectivity matrix\n",
    "        linkFiles = 'clink_thr' + str(zeropad(thr)) + '.clu'\n",
    "        mod = np.genfromtxt(subj + '/modOut/' + linkFiles, delimiter=None)\n",
    "        df_mod = pd.DataFrame(mod, columns=['node_ID', 'module', 'flow'])\n",
    "\n",
    "        # consensus matrix at next threshold\n",
    "        consMat2 = np.zeros((333,333))\n",
    "        for roi in range(1,334):\n",
    "            roi_mask = df_mod.isin([roi])\n",
    "            row_roi = list(roi_mask['node_ID'][roi_mask['node_ID'] == True].index)\n",
    "            for roi2 in range(1,334):\n",
    "                roi2_mask = df_mod.isin([roi2])\n",
    "                row_roi2 = list(roi2_mask['node_ID'][roi2_mask['node_ID'] == True].index)\n",
    "                if (df_mod.loc[row_roi,'module'].values == df_mod.loc[row_roi2,'module'].values):\n",
    "                    consMat2[roi-1,roi2-1] = 1\n",
    "\n",
    "        # find modules consisting of at least five ROIs\n",
    "        ms = []\n",
    "        for m in list(set(mod[:,1])):\n",
    "            if np.count_nonzero(mod[:,1] == m) >= 5:\n",
    "                ms.append(m)\n",
    "        df_mod_surv = df_mod[df_mod['module'].isin(ms)]\n",
    "\n",
    "        # find connections survived at each threshold\n",
    "        netFiles = 'clink_thr' + str(zeropad(thr)) + '.net'\n",
    "        conn = np.genfromtxt(subj + '/' + netFiles, delimiter=None)\n",
    "        df_conn = pd.DataFrame(conn, columns=['node_X', 'node_Y', 'connectivity'])\n",
    "\n",
    "        # update consensus matrix\n",
    "        for roi in df_mod_surv['node_ID'].values:  # iterate in survived modules\n",
    "            for roi2 in df_mod_surv['node_ID'].values:\n",
    "                if (df_conn['node_X'].isin([roi]) & df_conn['node_Y'].isin([roi2])).any():  # iterate in survived connections\n",
    "                    consMat[int(roi-1),int(roi2-1)] = consMat2[int(roi-1),int(roi2-1)] \n",
    "\n",
    "    np.savetxt('consMats/consMat_' + subj + '.csv', consMat, delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parallel processing\n",
    "if __name__ == '__main__':\n",
    "    # num_cores = multiprocessing.cpu_count()\n",
    "    # max num_cores = 128\n",
    "\n",
    "    pool = Pool(processes=20)\n",
    "    mp_results = pool.map(processInput, [subj for subj in subjDirs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
